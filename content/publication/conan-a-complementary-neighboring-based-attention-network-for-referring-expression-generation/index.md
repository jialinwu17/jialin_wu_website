---
title: "CoNAN: A Complementary Neighboring-based Attention Network for Referring
  Expression Generation"
publication_types:
  - "1"
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
abstract:
  Daily scenes are complex in the real world due to occlusion, undesired lighting conditions, etc. Although humans handle those complicated environments relatively well, they evoke challenges for machine learning systems to identify and describe the target without ambiguity. Previous studies focus on the context of the target object by comparing objects within the same category and utilizing the cycle-consistency between listener and speaker modules. However, it is still very challenging to mine the discriminative features of the target object on forming unambiguous expression. In this work, we propose a novel Complementary Neighboring-based Attention Network (CoNAN) that explicitly utilizes the visual differences between the target object and its highly-related neighbors. These highly-related neighbors are determined by an attentional ranking module, as complementary features, highlighting the discriminating aspects for the target object. The speaker module then takes the visual difference features as an additional input to generate the expression. Our qualitative and quantitative results on the dataset RefCOCO, RefCOCO+, and RefCOCOg demonstrates that our generated expressions outperform other state-of-the-art models by a clear margin.  
date: 2020-12-23T15:06:36.976Z
---
